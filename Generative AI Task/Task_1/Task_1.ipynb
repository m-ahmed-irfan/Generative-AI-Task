{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ac20f8-43b6-4f7b-a500-bc14e12894b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "\n",
    "from fpdf import FPDF\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e3c8f7-904a-4d75-878b-7e59812e7af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "SUMMARIZER_MODEL = \"gpt-4o-mini-2024-07-18\"\n",
    "MAX_TOKENS = 400   # Approximate number of tokens to fit into a page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de091b7-e3c5-42b8-8f9d-4d2236b74596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text):\n",
    "    \"\"\"\n",
    "    This function summarizes the input text using GPT.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=SUMMARIZER_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes text chunks provided from books.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Summarize the following text: {text}\"}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=MAX_TOKENS\n",
    "    )\n",
    "    summary = response.choices[0].message.content\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14cd615-a0c6-4a2a-9460-b1a87920e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_unicode_characters(text):\n",
    "    unicode_alternatives = {\n",
    "        \"–\": \"-\", \"—\": \"-\", \"―\": \"-\", \"‗\": \"=\", \"‘\": \"'\", \"’\": \"'\", \"‚\": \",\", \"‛\": \"'\",\n",
    "        \"“\": '\"', \"”\": '\"', \"•\": \"->\", \"′\": \"'\", \"″\": '\"', \"‹\": \"<\", \"›\": \">\"\n",
    "    }\n",
    "    for key, value in unicode_alternatives.items():\n",
    "        if key in text:\n",
    "            key = key.replace(key, value)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1113492d-238c-45a2-ac29-e28d36d63138",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDF(FPDF):\n",
    "    def chapter_title(self, title):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, title, ln=True, align='C')\n",
    "        self.ln(10)\n",
    "\n",
    "    def chapter_body(self, body):\n",
    "        self.set_font('Arial', '', 12)\n",
    "        self.multi_cell(0, 10, body)\n",
    "        self.ln()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf05586-55f3-456a-93eb-19ea42785313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pdf(summary_filepath, summaries):\n",
    "    \"\"\"\n",
    "    This function creates a PDF file for the text chunks provided.\n",
    "    \"\"\"\n",
    "    pdf = PDF()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "    pdf.add_page()\n",
    "    pdf.chapter_title(\"Summary of Crime and Punishment\")\n",
    "    for chapter_num, summary in enumerate(summaries, start=1):\n",
    "        summary = replace_unicode_characters(summary)\n",
    "        try:\n",
    "            summary = summary.encode(\"latin-1\", \"replace\").decode(\"latin-1\")\n",
    "        except UnicodeEncodeError as e:\n",
    "            print(f\"Encoding error in chapter {chapter_num}: {e}\")\n",
    "        pdf.chapter_title(f\"Chapter {chapter_num}\")\n",
    "        pdf.chapter_body(summary)\n",
    "    pdf.output(summary_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a65b7ab-86c3-4de1-a6cb-75be8b87bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_text(filepath):\n",
    "    \"\"\"\n",
    "    This functions extracts all text from the book\n",
    "    \"\"\"\n",
    "    book_text = \"\"\n",
    "    with fitz.open(filepath) as pdf:\n",
    "        for page in pdf:\n",
    "            book_text += page.get_text()\n",
    "    return book_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390168d2-ac53-42a5-bb87-0fd144383083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_chunks(book_text, number_of_pages):\n",
    "    \"\"\"\n",
    "    This function breaks down the book into chunks\n",
    "    \"\"\"\n",
    "    chunk_size = int(len(book_text) / number_of_pages)\n",
    "\n",
    "    chunks = []\n",
    "    start_index = end_index = 0\n",
    "    for i in range(number_of_pages):\n",
    "        start_index = end_index\n",
    "        end_index = i * chunk_size\n",
    "        # Ensure that each chunk ends at the end of a sentence rather than in the middle of a sentence or word.\n",
    "        if book_text[end_index] != '.':\n",
    "            remaining_chunk = book_text[end_index:]\n",
    "            next_dot = remaining_chunk.find('.')\n",
    "            end_index += next_dot\n",
    "        chunk = book_text[start_index:end_index]\n",
    "        if len(chunk) > 100:\n",
    "            chunks.append(chunk)\n",
    "\n",
    "    if len(chunks) == 20:\n",
    "        chunks[19] += book_text[end_index:]\n",
    "    elif len(chunks) == 19:\n",
    "        chunks.append(book_text[end_index:])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f1ec0-d971-4ea7-82a5-745e9b7cdebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    filepath = \"C:/Users/Dell/Documents/RhodiumTech/MedAI/Code/My Code/Generative AI Task/crime_and_punishment.pdf\"\n",
    "    book_text = get_book_text(filepath)\n",
    "    \n",
    "    number_of_pages = 20\n",
    "    chunks = get_book_chunks(book_text, number_of_pages)\n",
    "    \n",
    "    summarized_chunks = []\n",
    "    for chunk in chunks:\n",
    "        summary = summarize_text(chunk)\n",
    "        summarized_chunks.append(summary)\n",
    "\n",
    "    summary_filepath = \"Crime_and_Punishment_Summary.pdf\" # Add path for \n",
    "    create_pdf(summary_filepath, summarized_chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
